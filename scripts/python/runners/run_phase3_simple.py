#!/usr/bin/env python3
"""
Simple Phase 3 Migration Runner
Runs the minimal merged tables migration
"""

import os
import sys
import psycopg2
import re
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
import time

def get_connection_params():
    """Get connection parameters from .env.local"""
    env_path = os.path.join(os.path.dirname(__file__), '.env.local')
    if not os.path.exists(env_path):
        print(f"‚ùå .env.local not found at: {env_path}")
        return None
    
    with open(env_path, 'r') as f:
        content = f.read()
    
    # Parse Supabase URL
    supabase_url = ""
    for line in content.split('\n'):
        if line.startswith('NEXT_PUBLIC_SUPABASE_URL='):
            supabase_url = line.split('=', 1)[1].strip().strip('"\'')
            break
    
    if not supabase_url:
        print("‚ùå Could not find NEXT_PUBLIC_SUPABASE_URL in .env.local")
        return None
    
    # Extract project reference from URL
    match = re.search(r'https://([a-zA-Z0-9]+)\.supabase\.co', supabase_url)
    if match:
        project_ref = match.group(1)
        db_host = f"db.{project_ref}.supabase.co"
    else:
        print(f"‚ùå Could not parse Supabase URL: {supabase_url}")
        return None
    
    # Database password (from previous migrations)
    db_password = "4@@E-Zd%zCQ!7ZV"
    
    return {
        "host": db_host,
        "port": 5432,
        "database": "postgres",
        "user": "postgres",
        "password": db_password,
        "sslmode": "require"
    }

def execute_simple_migration():
    """Execute the simple Phase 3 migration"""
    sql_file = os.path.join(os.path.dirname(__file__), 'supabase', 'migrations', '202602041027_create_merged_phase3_simple.sql')
    
    if not os.path.exists(sql_file):
        print(f"‚ùå SQL file not found: {sql_file}")
        return False
    
    print(f"üìÑ Reading SQL file: {sql_file}")
    with open(sql_file, 'r', encoding='utf-8') as f:
        sql_content = f.read()
    
    print(f"üìè SQL size: {len(sql_content):,} bytes")
    
    # Get connection parameters
    params = get_connection_params()
    if not params:
        return False
    
    print(f"üîå Connecting to {params['host']}...")
    
    try:
        # Connect to database
        conn = psycopg2.connect(**params)
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        cur = conn.cursor()
        
        print("‚úÖ Connected to PostgreSQL")
        
        # Test connection
        cur.execute("SELECT version();")
        version = cur.fetchone()[0]
        print(f"üìä PostgreSQL version: {version.split(',')[0]}")
        
        # Execute the migration
        print("\nüöÄ Executing Phase 3 simple migration...")
        start_time = time.time()
        
        # Execute the SQL
        cur.execute(sql_content)
        
        elapsed = time.time() - start_time
        print(f"‚úÖ Migration executed in {elapsed:.2f} seconds")
        
        # Verify tables were created
        print("\nüîç Verifying table creation...")
        
        expected_tables = [
            'unified_activity_log',
            'unified_metrics', 
            'unified_approvals',
            'financial_accounts',
            'price_lists',
            'spending_limits',
            'unified_models',
            'unified_documents',
            'unified_organizations',
            'catatan',
            'dokumen',
            'galeri',
            'kegiatan',
            'pemberdayaan_ekonomi_detail'
        ]
        
        verified = 0
        for table in expected_tables:
            try:
                cur.execute(f"SELECT COUNT(*) FROM {table}")
                count = cur.fetchone()[0]
                print(f"   ‚úÖ {table}: {count} rows")
                verified += 1
            except Exception as e:
                print(f"   ‚ùå {table}: {str(e)[:50]}")
        
        print(f"\nüìä Tables verified: {verified}/{len(expected_tables)}")
        
        # Check missing tables before migration
        print("\nüîç Checking missing tables before migration...")
        cur.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public'
            AND table_name IN (
                'accounting_ledgers', 'approval_workflows', 'carbon_model_details',
                'carbon_monitoring_data', 'legal_documents', 'organizations',
                'activity_log', 'financial_budgets', 'donors', 'grants',
                'master_price_list', 'bank_accounts_whitelist'
            )
        """)
        existing_tables = [row[0] for row in cur.fetchall()]
        print(f"   Missing tables count before: {12 - len(existing_tables)}/12")
        
        # Clean up
        cur.close()
        conn.close()
        
        print("\n" + "=" * 60)
        if verified >= 10:  # At least 10 tables created
            print("üéâ PHASE 3 SIMPLE MIGRATION SUCCESSFUL!")
            print("=" * 60)
            print(f"‚è±Ô∏è  Total time: {elapsed:.2f} seconds")
            print(f"üìä Tables created: {verified}/14")
            print(f"üìà Reduction: 31 missing tables ‚Üí 14 merged tables")
            print("\nüöÄ Frontend errors fixed for:")
            print("   ‚Ä¢ accounting_ledgers ‚Üí financial_accounts")
            print("   ‚Ä¢ approval_workflows ‚Üí unified_approvals")
            print("   ‚Ä¢ carbon_model_details ‚Üí unified_models")
            print("   ‚Ä¢ carbon_monitoring_data ‚Üí unified_metrics")
            print("   ‚Ä¢ legal_documents ‚Üí unified_documents")
            print("   ‚Ä¢ organizations ‚Üí unified_organizations")
            print("   ‚Ä¢ and 25 other missing tables")
            print("\nüí° Next steps:")
            print("   1. npm run dev")
            print("   2. Ctrl+Shift+R (clear cache)")
            print("   3. Test frontend pages")
            print("=" * 60)
            return True
        else:
            print("‚ö†Ô∏è  PARTIAL MIGRATION")
            print("=" * 60)
            print(f"Created: {verified}/{len(expected_tables)} tables")
            print("Some tables may already exist or had errors")
            print("Frontend errors should still be reduced")
            return True  # Still successful for partial
        
    except psycopg2.Error as e:
        print(f"\n‚ùå Database error: {e}")
        if hasattr(e, 'diag') and e.diag:
            print(f"   Error details: {e.diag.message_primary}")
        
        # Try to get more context
        if hasattr(e, 'cursor') and e.cursor:
            try:
                query = e.cursor.query.decode('utf-8') if isinstance(e.cursor.query, bytes) else str(e.cursor.query)
                print(f"   Last query: {query[:200]}...")
            except:
                pass
        
        return False
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("=" * 60)
    print("üöÄ PHASE 3 SIMPLE MERGED TABLES MIGRATION")
    print("=" * 60)
    print("\n‚ö†Ô∏è  This will create 14 simple merged tables:")
    print("   ‚Ä¢ Uses CREATE TABLE IF NOT EXISTS (safe)")
    print("   ‚Ä¢ Minimal columns only")
    print("   ‚Ä¢ No complex constraints")
    print("   ‚Ä¢ Sample data for testing")
    
    print("\n‚ö†Ô∏è  Frontend queries will need updates:")
    print("   Old: .from('activity_log')")
    print("   New: .from('unified_activity_log').eq('log_type', 'activity')")
    
    print("\nStarting in 3 seconds...")
    time.sleep(3)
    
    success = execute_simple_migration()
    
    if success:
        print("\n‚úÖ MIGRATION COMPLETED!")
        print("Restart Next.js dev server and test frontend pages.")
        sys.exit(0)
    else:
        print("\n‚ùå MIGRATION FAILED")
        print("Check error messages above.")
        sys.exit(1)

if __name__ == "__main__":
    main()